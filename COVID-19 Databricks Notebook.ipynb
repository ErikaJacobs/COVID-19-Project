{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Connect to AWS - Save Final Product\n",
    "\n",
    "aws_access_key_id = ACCESS_KEY\n",
    "aws_secret_access_key = SECRET_KEY\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsAccessKeyId\", aws_access_key_id)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3n.awsSecretAccessKey\", aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "import dateutil.relativedelta\n",
    "import pandas\n",
    "\n",
    "# Setting Current Date - Based on Run Date\n",
    "now = (datetime.date(datetime.now()))\n",
    "\n",
    "# Is Today's CSV File Available? \n",
    "# If not, \"today\" actually needs to be yesterday\n",
    "\n",
    "def whenistoday():\n",
    "  today = now.strftime(\"%m-%d-%Y\")\n",
    "  \n",
    "  try:\n",
    "    csv_path = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{}.csv'.format(today)\n",
    "    # Path Test\n",
    "    df = pandas.read_csv(csv_path, nrows = 5)\n",
    "    return(today)\n",
    "  except:\n",
    "    today = (now - timedelta(days = 1)).strftime(\"%m-%d-%Y\")\n",
    "    return(today)\n",
    "\n",
    "today = whenistoday()\n",
    "\n",
    "if now != today:\n",
    "  now = (now - timedelta(days = 1))\n",
    "  \n",
    "# Setting Other Relative Dates\n",
    "yesterday = (now - timedelta(days = 1)).strftime(\"%m-%d-%Y\")\n",
    "twoday = (now - timedelta(days = 2)).strftime(\"%m-%d-%Y\")\n",
    "threeday = (now - timedelta(days = 3)).strftime(\"%m-%d-%Y\")\n",
    "fourday = (now - timedelta(days = 4)).strftime(\"%m-%d-%Y\")\n",
    "fiveday = (now - timedelta(days = 5)).strftime(\"%m-%d-%Y\")\n",
    "sixday = (now - timedelta(days = 6)).strftime(\"%m-%d-%Y\")\n",
    "oneweek = (now - timedelta(days = 7)).strftime(\"%m-%d-%Y\")\n",
    "eightday = (now - timedelta(days = 8)).strftime(\"%m-%d-%Y\")\n",
    "twoweek = (now - timedelta(days = 14)).strftime(\"%m-%d-%Y\")\n",
    "threeweek = (now - timedelta(days = 21)).strftime(\"%m-%d-%Y\")\n",
    "\n",
    "# Setting Relative Date - One Month Ago\n",
    "# onemonth = now - dateutil.relativedelta.relativedelta(months=1)\n",
    "# onemonth = datetime.strptime(str(onemonth) , '%Y-%m-%d').strftime(\"%m-%d-%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare Loop for Import\n",
    "\n",
    "from pyspark import SparkFiles, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import boto3\n",
    "\n",
    "timeframes = [today, yesterday, twoday, threeday, fourday, fiveday, sixday, oneweek, eightday, twoweek, threeweek]\n",
    "\n",
    "# Clear Old Files\n",
    "def DeleteDailyReports():\n",
    "  s3 = boto3.resource('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "  bucket = s3.Bucket('erikatestbucket')\n",
    "  bucket.objects.filter(Prefix=\"COVID-19/DailyReports\").delete()\n",
    "\n",
    "DeleteDailyReports()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loop to import files from Johns Hopkins CSSEGIS GitHub\n",
    "\n",
    "for time in timeframes:\n",
    "  url = 'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports/{}.csv'.format(time)\n",
    "  \n",
    "  # Read CSV via Pandas\n",
    "  pandasdf = pandas.read_csv(url)\n",
    "  \n",
    "  # Write CSV via Pandas\n",
    "  \n",
    "  bytes_to_write = pandasdf.to_csv(None, index = False).encode()\n",
    "  fs = s3fs.S3FileSystem(key=aws_access_key_id, secret=aws_secret_access_key)\n",
    "  with fs.open('s3://erikatestbucket/COVID-19/DailyReports/{}.csv'.format(time), 'wb') as f:\n",
    "    f.write(bytes_to_write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# UDF to Import Tables (Without using dictionary)\n",
    "def importdf(time):\n",
    "  df = spark.read.csv('s3://erikatestbucket/COVID-19/DailyReports/{}.csv'.format(time), header = True, inferSchema = True)\n",
    "  return(df)\n",
    "\n",
    "# Import Tables\n",
    "dftoday = importdf(today)\n",
    "dfyesterday = importdf(yesterday)\n",
    "dftwoday = importdf(twoday)\n",
    "dfthreeday = importdf(threeday)\n",
    "dffourday = importdf(fourday)\n",
    "dffiveday = importdf(fiveday)\n",
    "dfsixday = importdf(sixday)\n",
    "dfoneweek = importdf(oneweek)\n",
    "dfeightday = importdf(eightday)\n",
    "dftwoweek = importdf(twoweek)\n",
    "dfthreeweek = importdf(threeweek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prepare Other DFs for Join - Rename Fields\n",
    "# Loop/UDF Later\n",
    "\n",
    "from pyspark.sql import functions as sf\n",
    "\n",
    "def cleantable(df, num):\n",
    "  if df == dftoday:\n",
    "    df = df.select('Combined_Key', 'Admin2', 'Province_State', 'Country_Region', 'Confirmed', 'Deaths', 'Recovered', 'Active')\\\n",
    "    .withColumnRenamed('Confirmed', 'Confirmed_{}'.format(num))\\\n",
    "    .withColumnRenamed('Deaths', 'Deaths_{}'.format(num))\\\n",
    "    .withColumnRenamed('Recovered', 'Recovered_{}'.format(num))\\\n",
    "    .withColumnRenamed('Active', 'Active_{}'.format(num))\n",
    "  else:\n",
    "     df = df.select('Combined_Key', 'Confirmed', 'Deaths', 'Recovered', 'Active')\\\n",
    "    .withColumnRenamed('Confirmed', 'Confirmed_{}'.format(num))\\\n",
    "    .withColumnRenamed('Deaths', 'Deaths_{}'.format(num))\\\n",
    "    .withColumnRenamed('Recovered', 'Recovered_{}'.format(num))\\\n",
    "    .withColumnRenamed('Active', 'Active_{}'.format(num))\n",
    "      \n",
    "  return df\n",
    "\n",
    "df = cleantable(dftoday, '0')\n",
    "dfyesterday = cleantable(dfyesterday, '1')\n",
    "dftwoday = cleantable(dftwoday, '2')\n",
    "dfthreeday= cleantable(dfthreeday, '3')\n",
    "dffourday = cleantable(dffourday, '4')\n",
    "dffiveday = cleantable(dffiveday, '5')\n",
    "dfsixday = cleantable(dfsixday, '6')\n",
    "dfoneweek = cleantable(dfoneweek, '7')\n",
    "dfeightday = cleantable(dfeightday, '8')\n",
    "dftwoweek = cleantable(dftwoweek, '14')\n",
    "dfthreeweek = cleantable(dfthreeweek, '21')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\">Out[412]: True</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Join Tables Together\n",
    "\n",
    "tables = [dfyesterday, dftwoday, dfthreeday, dffourday, dffiveday, dfsixday, dfoneweek, dfeightday, dftwoweek, dfthreeweek]\n",
    "\n",
    "def join(df, table):\n",
    "  df = df.join(table, 'Combined_Key', \"left_outer\")\n",
    "  return df\n",
    "\n",
    "for t in tables:\n",
    "  df = join(df, t)\n",
    "  \n",
    "# Check that row count remains the same\n",
    "df.count() == dftoday.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Aggregate States - Drop Counties and Combined Key\n",
    "# Reduce Tables To Topics\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "def ReduceTables(Newdf):\n",
    "  Dict = {dfActive: 'Active', dfDeaths: 'Deaths', dfRecovered: 'Recovered', dfConfirmed: 'Confirmed'} \n",
    "  dftype = Dict.get(Newdf)\n",
    "\n",
    "  Newdf = df.groupBy('Province_State', 'Country_Region')\\\n",
    "  .agg(F.sum(\"{}_0\".format(dftype)).alias(\"{}_0\".format(dftype)),\n",
    "  F.sum(\"{}_1\".format(dftype)).alias(\"{}_1\".format(dftype)),\n",
    "  F.sum(\"{}_2\".format(dftype)).alias(\"{}_2\".format(dftype)),\n",
    "  F.sum(\"{}_3\".format(dftype)).alias(\"{}_3\".format(dftype)),\n",
    "  F.sum(\"{}_4\".format(dftype)).alias(\"{}_4\".format(dftype)),\n",
    "  F.sum(\"{}_5\".format(dftype)).alias(\"{}_5\".format(dftype)),\n",
    "  F.sum(\"{}_6\".format(dftype)).alias(\"{}_6\".format(dftype)),\n",
    "  F.sum(\"{}_7\".format(dftype)).alias(\"{}_7\".format(dftype)),\n",
    "  F.sum(\"{}_8\".format(dftype)).alias(\"{}_8\".format(dftype)),\n",
    "  F.sum(\"{}_14\".format(dftype)).alias(\"{}_14\".format(dftype)),\n",
    "  F.sum(\"{}_21\".format(dftype)).alias(\"{}_21\".format(dftype)))\n",
    "  return Newdf\n",
    "\n",
    "dfActive = ReduceTables(dfActive)\n",
    "dfDeaths = ReduceTables(dfDeaths)\n",
    "dfRecovered = ReduceTables(dfRecovered)\n",
    "dfConfirmed = ReduceTables(dfConfirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Adding Daily New Cases Columns\n",
    "\n",
    "def AddColumns(df):  \n",
    "  Dict = {dfActive: 'Active', dfDeaths: 'Deaths', dfRecovered: 'Recovered', dfConfirmed: 'Confirmed'} \n",
    "  dftype = Dict.get(df)\n",
    "\n",
    "  for i in list(range(0, 8)):\n",
    "    now = i\n",
    "    then = i+1\n",
    "    df = df.withColumn('{}New_{}'.format(dftype, now), df['{}_{}'.format(dftype, now)] - df['{}_{}'.format(dftype, then)])\n",
    "  return df\n",
    "\n",
    "dfConfirmed = AddColumns(dfActive)\n",
    "dfDeaths = AddColumns(dfDeaths)\n",
    "dfRecovered = AddColumns(dfRecovered)\n",
    "dfActive = AddColumns(dfActive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Clear Old Files\n",
    "def DeleteOutput():\n",
    "  s3 = boto3.resource('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "  bucket = s3.Bucket('erikatestbucket')\n",
    "  bucket.objects.filter(Prefix=\"COVID-19/Output\").delete()\n",
    "\n",
    "DeleteOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .ansiout {\n",
       "    display: block;\n",
       "    unicode-bidi: embed;\n",
       "    white-space: pre-wrap;\n",
       "    word-wrap: break-word;\n",
       "    word-break: break-all;\n",
       "    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n",
       "    font-size: 13px;\n",
       "    color: #555;\n",
       "    margin-left: 4px;\n",
       "    line-height: 19px;\n",
       "  }\n",
       "</style>\n",
       "<div class=\"ansiout\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Output = [dfConfirmed, dfDeaths, dfRecovered, dfActive]\n",
    "\n",
    "for df in Output:\n",
    "  Dict = {dfActive: 'Active', dfDeaths: 'Deaths', dfRecovered: 'Recovered', dfConfirmed: 'Confirmed'} \n",
    "  dftype = Dict.get(df)\n",
    "  \n",
    "  url = 's3a://erikatestbucket/COVID-19/Output/{}'.format(dftype)\n",
    "  # S3 (CSV)\n",
    "  df.coalesce(1).write.format(\"com.databricks.spark.csv\").option(\"header\", \"true\").save(url)\n",
    "  \n",
    "  \n",
    "  # Get Filename of \"Path\" that CSV is saved to\n",
    "  BucketList = []\n",
    "  bucket = s3.Bucket('erikatestbucket')\n",
    "  BucketObjects = bucket.objects.filter(Prefix=\"COVID-19/Output/{}\".format(dftype))\n",
    "  \n",
    "  for object in BucketObjects:\n",
    "    BucketList.append(str(object))\n",
    "  \n",
    "  for object in BucketList:\n",
    "    if 'csv' in object:\n",
    "    \n",
    "      # Get csv filename\n",
    "      string = (object)\n",
    "      filenameind = string.index('part')\n",
    "      csvind = string.index('.csv')\n",
    "      oldfilename = string[filenameind:csvind+4]\n",
    "      newfilename = '{}.csv'.format(dftype)\n",
    "      \n",
    "      \n",
    "      deletepath = 'COVID-19/Output/{}/'.format(dftype)\n",
    "      newpath = 'COVID-19/Output/{}.csv'.format(dftype)\n",
    "      oldpath = 'erikatestbucket/COVID-19/Output/{}/{}'.format(dftype, oldfilename)\n",
    "\n",
    "      # Copy old CSV location to new\n",
    "      s3.Object('erikatestbucket', newpath).copy_from(CopySource=oldpath)\n",
    "      # Delete old loation\n",
    "      bucket.objects.filter(Prefix=deletepath).delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "name": "COVID-19 GitHub",
  "notebookId": 4334385660630029
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
